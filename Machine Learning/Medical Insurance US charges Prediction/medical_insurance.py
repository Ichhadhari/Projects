# -*- coding: utf-8 -*-
"""medical insurance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qzuLsEtm0JiCNS88FeXn1UkGBwLCazy5

## Content:-
    
This dataset contains 1338 rows of insured data, where the Insurance charges are given against the following attributes of the
insured: Age, Sex, BMI, Number of Children, Smoker and Region. There are no missing or undefined values in the dataset.

# 1. Proble Statement:-

Predicting the medical insurance price builds by the health insurance company of a person which lives US.

## Domian Knowledge

''' We have a dataset having  followings  columns having some information related to medical insurance '''

### Feature of datasets are as follows: 
    
    age: age of primary beneficiary.
        
    sex: insurance contractor
        gender:- Male , Famale
            
    bmi: Body mass index,providing an understanding of body.
        
    children: Number of children covered by health insurance / Number of dependents
        
    Smoker: Smoking
        
    region: the  beneficiary's residential area in the US, northeast, southeast, southwest, northwest.
        
    charges: Individual medical costs billed by health insurance.

# libraries -->
"""

import pandas as pd 
import numpy as np 

# data visualization#
import matplotlib.pyplot as plt 
import seaborn as sns

# models
from sklearn.linear_model import LinearRegression,Ridge,Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
import warnings 
warnings.filterwarnings('ignore')

"""# Data gathering -->"""

df = pd.read_csv(r"/content/medical_insurance.csv")
df

"""# Exploratory data anyalisis -->

"""

df['region'].unique()

df.info()

df.describe()

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder

L1=LabelEncoder()
df["sex"]=L1.fit_transform(df['sex'])
df['smoker']=L1.fit_transform(df['smoker'])

sex_value = {'female':0,'male':1}
smoker_value = {'yes':1,'no':0}

df = pd.get_dummies(df,columns= ['region'])
df



"""# Spliting Data"""

x = df.drop(['charges'],axis = 1)
y = df['charges']

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=15)

x_train.shape

"""# Model Training """

linear_reg_model = LinearRegression()
linear_reg_model.fit(x_train,y_train)

from sklearn.metrics import mean_squared_error

from sklearn.metrics import r2_score #sklearn.metrics.r2_score

"""# Train model without hyperparaeter"""

def train_model(x_train, y_train):
    
    tree = DecisionTreeRegressor(random_state=0)
    tree.fit(x_train,y_train)
    y_pred_tree = tree.predict(x_test)
#     model_details.append("Decision Tree without hyperparameter")
    
    rf = RandomForestRegressor(random_state=0)
    rf.fit(x_train,y_train)
    y_pred_rf = rf.predict(x_test)
#     model_details.append("Random Forest without Hyperparameter")
    
    knn = KNeighborsRegressor()
    knn.fit(x_train,y_train)
    y_pred_knn = knn.predict(x_test)
#     model_details.append("KNN without Hyperparaeter")
    
    lr = LinearRegression()
    lr.fit(x_train,y_train)
    y_pred_lr = lr.predict(x_test)
#     model_details.append("Linear Regression without Hyperparameter")
    

    
    # testing accuracy of DT 
    MSE_tree = mean_squared_error(y_test,y_pred_tree)
    MAE_tree = mean_squared_error(y_test,y_pred_tree)
    RMSE_tree = np.sqrt(MSE_tree)
    R2_score_tree_test = r2_score(y_test,y_pred_tree)
#     Testing_accuracy.append(R2_score_tree_test)
    
    # traing accuracy of DT 
    y_pred_train = tree.predict(x_train)
    MSE_tree = mean_squared_error(y_train,y_pred_train)
    MAE_tree = mean_squared_error(y_train,y_pred_train)
    RMSE_tree = np.sqrt(MSE_tree)
    R2_score_tree_train = r2_score(y_train,y_pred_train)
#     Training_accuracy.append(R2_score_tree_train)
    
    # testing accuracy of RF
    MSE_rf = mean_squared_error(y_test,y_pred_rf)
    MAE_rf = mean_squared_error(y_test,y_pred_rf)
    RMSE_rf = np.sqrt(MSE_rf)
    R2_score_rf_test = r2_score(y_test,y_pred_rf)
#     Testing_accuracy.append(R2_score_rf_test)
    
    # traing accuracy of RF
    y_pred_train = rf.predict(x_train)
    MSE_rf = mean_squared_error(y_train,y_pred_train)
    MAE_rf = mean_squared_error(y_train,y_pred_train)
    RMSE_rf = np.sqrt(MSE_rf)
    R2_score_rf_train = r2_score(y_train,y_pred_train)
#     Training_accuracy.append(R2_score_rf_train)
    
    # testing accuracy of KNN
    MSE_knn = mean_squared_error(y_test,y_pred_knn)
    MAE_knn = mean_squared_error(y_test,y_pred_knn)
    RMSE_knn = np.sqrt(MSE_knn)
    R2_score_knn_test = r2_score(y_test,y_pred_knn)
#     Testing_accuracy.append(R2_score_knn_test)
    
    # training accuracy of KNN
    y_pred_train = knn.predict(x_train)
    MSE_knn = mean_squared_error(y_train,y_pred_train)
    MAE_knn = mean_squared_error(y_train,y_pred_train)
    RMSE_knn = np.sqrt(MSE_knn)
    R2_score_knn_train = r2_score(y_train,y_pred_train)
#     Training_accuracy.append(R2_score_knn_train)
    
    # testing accuracy of LR
    MSE_lr = mean_squared_error(y_test,y_pred_lr)
    MAE_lr = mean_squared_error(y_test,y_pred_lr)
    RMSE_lr = np.sqrt(MSE_lr)
    R2_score_lr_test = r2_score(y_test,y_pred_lr)
#     Testing_accuracy.append(R2_score_lr_test)
    
    # training accuracy of LR
    y_pred_train = lr.predict(x_train)
    MSE_lr = mean_squared_error(y_train,y_pred_train)
    MAE_lr = mean_squared_error(y_train,y_pred_train)
    RMSE_lr = np.sqrt(MSE_lr)
    R2_score_lr_train = r2_score(y_train,y_pred_train)
#     Training_accuracy.append(R2_score_lr_train)
    
    
   
    print('[1]Decision Tree Testing Accurancy: ', R2_score_tree_test)
    
    print('Mean Absolute Error:', MAE_tree)
    print('Mean Square Error:', MSE_tree)
    print('Root Mean Square Error:', RMSE_tree)
    print('\t')
    
    print('[1]Decision Tree training Accurancy: ', R2_score_tree_train)
    print("\n")

    
    print('[2]RandomForestRegressor Testing Accurancy: ',R2_score_rf_test)
    print('Mean Absolute Error:', MAE_rf)
    print('Mean Square Error:', MSE_rf)
    print('Root Mean Square Error:', RMSE_rf)
    print('\t')    
    
    print('[2]RandomForestRegressor Training Accurancy: ',R2_score_rf_train)
    print("\n")
    
    print('[3]knn Testing Accurancy: ', R2_score_knn_test)
    print('Mean Absolute Error:', MAE_knn)
    print('Mean Square Error:', MSE_knn)
    print('Root Mean Square Error:', RMSE_knn)
    print('\t')
    print('[3]knn Training Accurancy: ', R2_score_knn_train)
    print("\n")
    
    print('[4]Lr Testing Accurancy: ', R2_score_lr_test)
    print('Mean Absolute Error:', MAE_lr)
    print('Mean Square Error:', MSE_lr)
    print('Root Mean Square Error:', RMSE_lr)
    print('\t')
    print('[4]Lr Training Accurancy: ', R2_score_lr_train)
    
    
train_model(x_train,y_train)



x_test

tree = DecisionTreeRegressor(random_state=0)
tree.fit(x_train,y_train)
y_pred_tree = tree.predict(x_test)

check=[[35,	1,	36.67,	1,	1,	1,	0,	0,	0]]

y_pred_tree_1 = tree.predict(check)

y_pred_tree_1

x_test.iloc[0:1]

#tree
# saving model as a pickle
import pickle
pickle.dump(tree,open("medical_insurance_ml_model.pkl", "wb"))

